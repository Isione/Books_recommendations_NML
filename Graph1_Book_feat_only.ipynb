{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import h5py"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:15.843420Z",
     "start_time": "2024-06-10T21:35:09.626875Z"
    }
   },
   "id": "aa254c2fc38985ca",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:15.859076Z",
     "start_time": "2024-06-10T21:35:15.843420Z"
    }
   },
   "id": "89b41687899a28b7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Loading data and processing data"
   ],
   "id": "52093d4b0c011ac8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:16.712526Z",
     "start_time": "2024-06-10T21:35:15.859076Z"
    }
   },
   "source": [
    "# Load csv file ratings, books_clean and user_fav_genres\n",
    "users_2_books = pd.read_csv('data/ratings.csv')\n",
    "books_2_genres = pd.read_csv('data/books_clean.csv', converters={\"genres\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").replace(\" \",\"\")})\n",
    "users_2_genres = pd.read_csv('data/user_genres.csv', converters={\"genres\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").replace(\" \",\"\")})"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Book features from genres"
   ],
   "id": "57f076d117019a5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:16.837564Z",
     "start_time": "2024-06-10T21:35:16.712526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "book_genres = books_2_genres['genres'].str.get_dummies(\",\")\n",
    "logger.info(f\"Book genres: {book_genres.columns}\")"
   ],
   "id": "98b7592d3088d816",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:16,821 - INFO - Book genres: Index(['art', 'biography', 'books', 'business', 'chick-lit', 'christian',\n",
      "       'classics', 'comics', 'contemporary', 'cookbooks', 'crime', 'fantasy',\n",
      "       'fiction', 'gay-and-lesbian', 'graphic-novels', 'historical-fiction',\n",
      "       'history', 'horror', 'humor-and-comedy', 'manga', 'memoir', 'music',\n",
      "       'mystery', 'nonfiction', 'paranormal', 'philosophy', 'poetry',\n",
      "       'psychology', 'religion', 'romance', 'science', 'science-fiction',\n",
      "       'self-help', 'spirituality', 'sports', 'suspense', 'thriller', 'travel',\n",
      "       'young-adult'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:16.853188Z",
     "start_time": "2024-06-10T21:35:16.837564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "book_feat = torch.from_numpy(book_genres.values).to(torch.float)\n",
    "assert book_feat.size() == (10000, 39)  "
   ],
   "id": "ef8fdefa3e641621",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## User features from genres"
   ],
   "id": "5f8483631b4f95de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:18.632980Z",
     "start_time": "2024-06-10T21:35:16.853188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_user_id = users_2_books['user_id'].unique()\n",
    "unique_user_id = np.sort(unique_user_id)\n",
    "\n",
    "# Now we want to make sure that all the user id are in the user_2_genres\n",
    "# We will add the missing user id with all genres as []\n",
    "counter = 0\n",
    "for user_id in unique_user_id:\n",
    "    if user_id not in users_2_genres[\"user_id\"].values:\n",
    "        counter += 1\n",
    "        df_to_append = pd.DataFrame([{\"user_id\": user_id, \"genres\": \"\"}])\n",
    "        users_2_genres = pd.concat([users_2_genres, df_to_append], ignore_index=True)\n",
    "\n",
    "logger.info(f\"Number of users added: {counter}\")"
   ],
   "id": "50b3226a5ece34ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:18,617 - INFO - Number of users added: 242\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:19.290404Z",
     "start_time": "2024-06-10T21:35:18.632980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_genres = users_2_genres['genres'].str.get_dummies(\",\")\n",
    "\n",
    "# Add the missing columns to the user_genres to have the same number of columns on user_genres and book_genres\n",
    "for column in book_genres.columns:\n",
    "    if column not in user_genres.columns:\n",
    "        user_genres[column] = 0\n",
    "        \n",
    "logger.info(f\"User genres: {user_genres.columns}\")\n",
    "\n",
    "user_genres.head()\n",
    "user_feat = torch.from_numpy(user_genres.values).to(torch.float)"
   ],
   "id": "9e317d0fe9cb8b97",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:19,259 - INFO - User genres: Index(['art', 'biography', 'books', 'business', 'chick-lit', 'christian',\n",
      "       'classics', 'comics', 'contemporary', 'cookbooks', 'crime', 'fantasy',\n",
      "       'fiction', 'graphic-novels', 'historical-fiction', 'history', 'horror',\n",
      "       'manga', 'memoir', 'music', 'mystery', 'nonfiction', 'paranormal',\n",
      "       'philosophy', 'poetry', 'psychology', 'religion', 'romance', 'science',\n",
      "       'science-fiction', 'self-help', 'spirituality', 'sports', 'suspense',\n",
      "       'thriller', 'travel', 'young-adult', 'gay-and-lesbian',\n",
      "       'humor-and-comedy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Edge Index and mapping between user and book"
   ],
   "id": "94e2bbb7096b099f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:19.353312Z",
     "start_time": "2024-06-10T21:35:19.290477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
    "unique_user_id = users_2_books['user_id'].unique()\n",
    "\n",
    "unique_user_id = np.sort(unique_user_id)\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'user_id': unique_user_id,\n",
    "    'mapped_id': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "\n",
    "logger.info(f\"Mapping of user IDs to consecutive values: \\n {unique_user_id.head()}\")\n"
   ],
   "id": "52053be9347b69d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:19,337 - INFO - Mapping of user IDs to consecutive values: \n",
      "    user_id  mapped_id\n",
      "0        1          0\n",
      "1        2          1\n",
      "2        3          2\n",
      "3        4          3\n",
      "4        5          4\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:19.415814Z",
     "start_time": "2024-06-10T21:35:19.353312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a mapping from unique book indices to range [0, num_book_nodes):\n",
    "unique_book_id = users_2_books['book_id'].unique()\n",
    "unique_book_id = np.sort(unique_book_id)\n",
    "unique_book_id = pd.DataFrame(data={\n",
    "    'book_id': unique_book_id,\n",
    "    'mapped_id': pd.RangeIndex(len(unique_book_id)),\n",
    "})\n",
    "\n",
    "logger.info(f\"Mapping of book IDs to consecutive values: \\n {unique_book_id.head()}\")"
   ],
   "id": "d1a12e17d3b0b113",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:19,400 - INFO - Mapping of book IDs to consecutive values: \n",
      "    book_id  mapped_id\n",
      "0        1          0\n",
      "1        2          1\n",
      "2        3          2\n",
      "3        4          3\n",
      "4        5          4\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:20.288455Z",
     "start_time": "2024-06-10T21:35:19.415814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform merge to obtain the edges from users and books:\n",
    "ratings_user_id = pd.merge(users_2_books['user_id'], unique_user_id,\n",
    "                            left_on='user_id', right_on='user_id', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mapped_id'].values)\n",
    "ratings_book_id = pd.merge(users_2_books['book_id'], unique_book_id,\n",
    "                            left_on='book_id', right_on='book_id', how='left')\n",
    "ratings_book_id = torch.from_numpy(ratings_book_id['mapped_id'].values)\n",
    "\n",
    "edge_index_user_to_book = torch.stack([ratings_user_id, ratings_book_id], dim=0)\n",
    "\n",
    "logger.info(f\"Final edge indices pointing from users to books: \\n {edge_index_user_to_book}\")         "
   ],
   "id": "3c8bd53cf3d53fd0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:20,272 - INFO - Final edge indices pointing from users to books: \n",
      " tensor([[    0,     1,     1,  ..., 49924, 49924, 49924],\n",
      "        [  257,  4080,   259,  ...,   721,   948,  1022]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hetero data initialization"
   ],
   "id": "134e70934ca59d64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:20.320066Z",
     "start_time": "2024-06-10T21:35:20.288455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "data[\"book\"].node_id = torch.arange(len(books_2_genres))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "data[\"book\"].x = book_feat\n",
    "data[\"user\"].x = user_feat\n",
    "\n",
    "data[\"user\", \"rates\", \"book\"].edge_index = edge_index_user_to_book\n",
    "\n",
    "# `T.ToUndirected()` makes sure to add the reverse edges from books to users to let the GNN pass messages in both directions.\n",
    "data = T.ToUndirected()(data)"
   ],
   "id": "bab229da276c01d5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "id": "50759bf3fa6f1fb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:20.335691Z",
     "start_time": "2024-06-10T21:35:20.320066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user: Tensor, x_book: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_book = x_book[edge_label_index[1]]\n",
    "        # Apply dot-product to get a prediction \n",
    "        return (edge_feat_user * edge_feat_book).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        self.book_lin = torch.nn.Linear(39, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "        self.book_emb = torch.nn.Embedding(data[\"book\"].num_nodes, hidden_channels)\n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "\n",
    "        # Convert GNN model into a heterogeneous:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "        self.classifier = Classifier()\n",
    "        \n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "          \"book\": self.book_lin(data[\"book\"].x) + self.book_emb(data[\"book\"].node_id),\n",
    "        } \n",
    "        \n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"book\"],\n",
    "            data[\"user\", \"rates\", \"book\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "        \n"
   ],
   "id": "1fd6fc96d188a6ff",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:20.351316Z",
     "start_time": "2024-06-10T21:35:20.335691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ground_truths = []\n",
    "    for sampled_data in tqdm.tqdm(val_loader):\n",
    "        with torch.no_grad():\n",
    "            sampled_data.to(device)\n",
    "            preds.append(model(sampled_data))\n",
    "            ground_truths.append(sampled_data[\"user\", \"rates\", \"book\"].edge_label)            \n",
    "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    auc = roc_auc_score(ground_truth, pred)\n",
    "    acc = balanced_accuracy_score(ground_truth, [sigmoid(pred[i]) >= 0.5 for i in range(len(pred))])\n",
    "    \n",
    "    return auc, acc\n",
    "\n",
    "def sigmoid(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def save_hetero_data(data: HeteroData, file_path: str) -> None:\n",
    "    with h5py.File(file_path, 'w') as f:\n",
    "        for node_type in data.node_types:\n",
    "            if 'x' in data[node_type]:\n",
    "                f.create_dataset(f'{node_type}/x', data=data[node_type].x.cpu().numpy())\n",
    "        for edge_type in data.edge_types:\n",
    "            f.create_dataset(f'{edge_type}/edge_index', data=data[edge_type].edge_index.cpu().numpy())\n",
    "            if 'edge_label' in data[edge_type]:\n",
    "                f.create_dataset(f'{edge_type}/edge_label', data=data[edge_type].edge_label.cpu().numpy())\n",
    "                \n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ground_truths = []\n",
    "    for sampled_data in tqdm.tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            sampled_data.to(device)\n",
    "            preds.append(model(sampled_data))\n",
    "            ground_truths.append(sampled_data[\"user\", \"rates\", \"book\"].edge_label)            \n",
    "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    auc = roc_auc_score(ground_truth, pred)\n",
    "    acc = balanced_accuracy_score(ground_truth, [sigmoid(pred[i]) >= 0.5 for i in range(len(pred))])\n",
    "    \n",
    "    return auc, acc"
   ],
   "id": "7d67a6808cf5a90",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Wandb Sweep"
   ],
   "id": "eb0df6b1fb6db3cc"
  },
  {
   "cell_type": "code",
   "source": [
    "#read the .env file\n",
    "wandb_token = os.getenv(\"NML_ACCESS_TOKEN\")\n",
    "wandb.login(key=wandb_token)\n",
    "\n",
    "# Initialize wandb\n",
    "wandb_project_name = 'Final_sweep_Book_feat_only'\n",
    "date_time = datetime.datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "day_time = datetime.datetime.now().strftime(\"%m_%d\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:22.488295Z",
     "start_time": "2024-06-10T21:35:20.351316Z"
    }
   },
   "id": "3432a952860e2e96",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: isione-bonvalot (isione). Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def upgrade_file_version(folder_path: str) -> int:\n",
    "    new_version = 1\n",
    "    for f in os.listdir(folder_path):\n",
    "        if f.startswith(f'{date_time}'):\n",
    "            file_path = os.path.join(folder_path, f) \n",
    "            version = file_path.split(\"_\")[-1].split(\".\")[0][1:]\n",
    "            new_version = int(version) + 1\n",
    "    return new_version\n",
    "# read sweep_config.yaml file\n",
    "with open(\"sweep_config.yaml\", 'r') as stream:\n",
    "    sweep_config = yaml.safe_load(stream)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=wandb_project_name)\n",
    "\n",
    "logger.info(f\"Sweep config: {sweep_config}\")\n",
    "logger.info(f\"Sweep id: {sweep_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:28.728483Z",
     "start_time": "2024-06-10T21:35:22.488295Z"
    }
   },
   "id": "bd9465c92150d39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: rvg6u7n9\n",
      "Sweep URL: https://wandb.ai/isione/Final_sweep_Book_feat_only/sweeps/rvg6u7n9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:28,697 - INFO - Sweep config: {'method': 'bayes', 'metric': {'name': 'Validation AUC', 'goal': 'maximize'}, 'parameters': {'hidden_channels': {'values': [32, 64, 128]}, 'lr': {'distribution': 'uniform', 'min': 0.0001, 'max': 0.01}, 'batch_size': {'distribution': 'q_log_uniform_values', 'q': 8, 'min': 32, 'max': 512}, 'epochs': {'value': 1}, 'loss': {'value': 'CrossEntropyLoss'}, 'optimizer': {'values': ['Adam', 'SGD']}, 'first_num_neighbours': {'values': [10, 20]}, 'second_num_neighbours': {'values': [10, 20]}, 'negative_sampling_ratio': {'values': [1, 2]}}}\n",
      "2024-06-10 23:35:28,697 - INFO - Sweep id: rvg6u7n9\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:28.807579Z",
     "start_time": "2024-06-10T21:35:28.728483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(config=None):\n",
    "    \n",
    "    with wandb.init(config=config):\n",
    "        \n",
    "        config = wandb.config\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Device: {device}\")\n",
    "    \n",
    "        # Create splits data\n",
    "        transform = T.RandomLinkSplit(\n",
    "            num_val=0.1,\n",
    "            num_test=0.1,\n",
    "            disjoint_train_ratio=0.3,\n",
    "            neg_sampling_ratio=config.negative_sampling_ratio,\n",
    "            add_negative_train_samples=False,\n",
    "            edge_types=(\"user\", \"rates\", \"book\"),\n",
    "            rev_edge_types=(\"book\", \"rev_rates\", \"user\"), \n",
    "        )\n",
    "        train_data, val_data, test_data = transform(data)\n",
    "        \n",
    "        # Create loaders\n",
    "        edge_label_index = train_data[\"user\", \"rates\", \"book\"].edge_label_index\n",
    "        edge_label = train_data[\"user\", \"rates\", \"book\"].edge_label\n",
    "        train_loader = LinkNeighborLoader(\n",
    "            data=train_data,\n",
    "            num_neighbors=[config.first_num_neighbours, config.second_num_neighbours],\n",
    "            neg_sampling_ratio=config.negative_sampling_ratio,\n",
    "            edge_label_index=((\"user\", \"rates\", \"book\"), edge_label_index),\n",
    "            edge_label=edge_label,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        edge_label_index = val_data[\"user\", \"rates\", \"book\"].edge_label_index\n",
    "        edge_label = val_data[\"user\", \"rates\", \"book\"].edge_label\n",
    "        val_loader = LinkNeighborLoader(\n",
    "            data=val_data,\n",
    "            num_neighbors=[config.first_num_neighbours, config.second_num_neighbours],\n",
    "            edge_label_index=((\"user\", \"rates\", \"book\"), edge_label_index),\n",
    "            edge_label=edge_label,\n",
    "            batch_size=(1+config.negative_sampling_ratio) * config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "        edge_label_index = test_data[\"user\", \"rates\", \"book\"].edge_label_index\n",
    "        edge_label = test_data[\"user\", \"rates\", \"book\"].edge_label\n",
    "        test_loader = LinkNeighborLoader(\n",
    "            data=test_data,\n",
    "            num_neighbors=[config.first_num_neighbours, config.second_num_neighbours],\n",
    "            edge_label_index=((\"user\", \"rates\", \"book\"), edge_label_index),\n",
    "            edge_label=edge_label,\n",
    "            batch_size=(1+config.negative_sampling_ratio) * config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "        model = Model(hidden_channels=config.hidden_channels)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        if config.optimizer == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "        elif config.optimizer == \"SGD\": \n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=config.lr)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer\")\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(f'models/book_feat_only/{day_time}_v000'):\n",
    "            version = 0\n",
    "        else: \n",
    "            folder_path_start = f'models/book_feat_only'\n",
    "            version = upgrade_file_version(folder_path_start) \n",
    "\n",
    "        os.makedirs(f'models/book_feat_only/{day_time}_v{int(version):03d}')\n",
    "        saving_path = f'models/book_feat_only/{day_time}_v{int(version):03d}'\n",
    "        logger.info(f\"Saving path: {saving_path}\")\n",
    "            \n",
    "        \n",
    "        #save test splits for future testings on the best model\n",
    "        test_set_path = saving_path + '/test_data.h5'\n",
    "        save_hetero_data(train_data, test_set_path)\n",
    "        logger.info(f\"Test data saved at: {test_set_path}\")\n",
    "        \n",
    "        metrics_dict = {}\n",
    "        \n",
    "        for epoch in range(0, config.epochs):\n",
    "            #Training \n",
    "            total_loss = total_examples = 0\n",
    "            pred_list = []\n",
    "            gt_list = []\n",
    "            for sampled_data in tqdm.tqdm(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                sampled_data.to(device)\n",
    "                pred = model(sampled_data)\n",
    "                ground_truth = sampled_data[\"user\", \"rates\", \"book\"].edge_label\n",
    "                if config.loss == \"CrossEntropyLoss\":\n",
    "                    loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid loss\")\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += float(loss) * pred.numel()\n",
    "                total_examples += pred.numel()\n",
    "                pred_list.extend(torch.sigmoid(pred).detach().cpu().numpy())\n",
    "                gt_list.extend(ground_truth.cpu().numpy())\n",
    "                \n",
    "            loss = total_loss / total_examples\n",
    "            acc_train = balanced_accuracy_score(gt_list, [pred_list[i] >= 0.5 for i in range(len(pred_list))])\n",
    "        \n",
    "            torch.save(model.state_dict(), saving_path + f'/model_epoch_{epoch}.pth')\n",
    "            \n",
    "            # Validatation\n",
    "            val_auc, acc_val = validate(model, val_loader, device)\n",
    "            \n",
    "            # Log the validation AUC to wandb\n",
    "            wandb.log({'epoch': epoch, 'Validation AUC': val_auc, 'Loss': loss ,'training accuracy': acc_train, 'validation_accuracy': acc_val})\n",
    "            logger.info(f\"Epoch {epoch} - Validation AUC: {val_auc:.4f} - Loss: {loss:.4f} - Training Accuracy: {acc_train:.4f} - Validation Accuracy: {acc_val:.4f}\")\n",
    "            \n",
    "            metrics_dict[epoch] = {\"loss\": loss, \"auc\": val_auc}\n",
    "            \n",
    "            #save metrics with pickle\n",
    "            with open(saving_path + '/metrics_dict.pkl', 'wb') as f:\n",
    "                pickle.dump(metrics_dict, f)\n",
    "        \n",
    "        torch.save(model.state_dict(), saving_path + f'/final_model.pth')\n",
    "        \n",
    "        # Test the model\n",
    "        with torch.no_grad():\n",
    "            test_auc, acc_test = test(model, test_loader, device)\n",
    "        \n",
    "        logger.info(f\"Test AUC: {test_auc:.4f} - Test Accuracy: {acc_test:.4f}\")\n",
    "        \n",
    "        # Finish the wandb run\n",
    "        wandb.finish()\n",
    "            "
   ],
   "id": "ea8252761f388bba",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:41:58.706317Z",
     "start_time": "2024-06-10T21:35:28.807579Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.agent(sweep_id, train, count=20)",
   "id": "4fbd9068fc8a22c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:28,807 - INFO - Starting sweep agent: entity=None, project=None, count=1\n",
      "wandb: Agent Starting Run: d4oyfmeo with config:\n",
      "wandb: \tbatch_size: 376\n",
      "wandb: \tepochs: 1\n",
      "wandb: \tfirst_num_neighbours: 20\n",
      "wandb: \thidden_channels: 32\n",
      "wandb: \tloss: CrossEntropyLoss\n",
      "wandb: \tlr: 0.003290506726477332\n",
      "wandb: \tnegative_sampling_ratio: 2\n",
      "wandb: \toptimizer: SGD\n",
      "wandb: \tsecond_num_neighbours: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Isione\\Documents\\NML_projet\\clean_code\\wandb\\run-20240610_233531-d4oyfmeo</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/isione/Final_sweep_Book_feat_only/runs/d4oyfmeo' target=\"_blank\">young-sweep-1</a></strong> to <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only/sweeps/rvg6u7n9' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only/sweeps/rvg6u7n9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only/sweeps/rvg6u7n9' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only/sweeps/rvg6u7n9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only/runs/d4oyfmeo' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only/runs/d4oyfmeo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:35:32,244 - INFO - Device: cuda\n",
      "2024-06-10 23:35:36,047 - INFO - Saving path: models/book_feat_only/06_10_v000\n",
      "2024-06-10 23:35:36,141 - INFO - Test data saved at: models/book_feat_only/06_10_v000/test_data.h5\n",
      "100%|██████████| 3815/3815 [03:40<00:00, 17.33it/s]\n",
      "100%|██████████| 1590/1590 [01:08<00:00, 23.11it/s]\n",
      "2024-06-10 23:40:38,675 - INFO - Epoch 0 - Validation AUC: 0.5178 - Loss: 0.6461 - Training Accuracy: 0.4999 - Validation Accuracy: 0.5001\n",
      "100%|██████████| 1590/1590 [01:08<00:00, 23.26it/s]\n",
      "2024-06-10 23:41:52,795 - INFO - Test AUC: 0.5139 - Test Accuracy: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "062996b92513483b9ebcc7d6c845fb65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▁</td></tr><tr><td>Validation AUC</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>training accuracy</td><td>▁</td></tr><tr><td>validation_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.64611</td></tr><tr><td>Validation AUC</td><td>0.51783</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>training accuracy</td><td>0.49991</td></tr><tr><td>validation_accuracy</td><td>0.50009</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-1</strong> at: <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only/runs/d4oyfmeo' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only/runs/d4oyfmeo</a><br/> View project at: <a href='https://wandb.ai/isione/Final_sweep_Book_feat_only' target=\"_blank\">https://wandb.ai/isione/Final_sweep_Book_feat_only</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240610_233531-d4oyfmeo\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [],
   "id": "51ba06ac5e70eb85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
